{% extends "base.html" %}

{% block title %}Model Information - Medical Image Enhancement{% endblock %}

{% block content %}
<div class="container py-5">
    <h1 class="display-4 text-center mb-5">Our AI Models</h1>
    
    <!-- SRCNN Model -->
    <div class="card shadow-sm mb-4">
        <div class="card-header bg-primary text-white">
            <h2 class="h4 mb-0">SRCNN (Super-Resolution CNN)</h2>
        </div>
        <div class="card-body">
            <div class="row">
                <div class="col-md-6">
                    <h5 class="card-subtitle mb-3">Architecture Overview</h5>
                    <p class="lead">A deep learning model specifically designed for image super-resolution and enhancement.</p>
                    <div class="alert alert-info">
                        <h6>Model Specifications:</h6>
                        <ul class="list-unstyled mb-3">
                            <li><strong>Parameters:</strong> 57,184</li>
                            <li><strong>Input Size:</strong> 299×299×3</li>
                            <li><strong>Output Size:</strong> 299×299×3</li>
                            <li><strong>File Size:</strong> 228 KB</li>
                        </ul>
                        <h6>Model Architecture:</h6>
                        <pre class="bg-light p-3 mb-0" style="max-height: 300px; overflow-y: auto;"><code class="python"># SRCNN Model Architecture
class SRCNN(nn.Module):
    def __init__(self):
        super(SRCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)
        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)
        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)
        self.relu = nn.ReLU(inplace=True)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = self.relu(self.conv2(x))
        x = self.conv3(x)
        return x</code></pre>
                    </div>
                </div>
                <div class="col-md-6">
                    <h5 class="mb-3">Key Features</h5>
                    <ul class="list-group">
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Feature extraction layer (9×9 conv)</li>
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Non-linear mapping layer (1×1 conv)</li>
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Reconstruction layer (5×5 conv)</li>
                    </ul>
                    <div class="mt-4">
                        <h5 class="mb-3">Advantages</h5>
                        <ul class="list-unstyled">
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>End-to-end learning of mapping functions</li>
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>Lightweight architecture for efficient processing</li>
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>Specialized in medical image enhancement</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- U-Net Model -->
    <div class="card shadow-sm mb-4">
        <div class="card-header bg-success text-white">
            <h2 class="h4 mb-0">U-Net Architecture</h2>
        </div>
        <div class="card-body">
            <div class="row">
                <div class="col-md-6">
                    <h5 class="card-subtitle mb-3">Architecture Overview</h5>
                    <p>A convolutional network architecture designed for biomedical image segmentation and enhancement.</p>
                    <div class="alert alert-info">
                        <h6>Model Specifications:</h6>
                        <ul class="list-unstyled mb-3">
                            <li><strong>Parameters:</strong> 7,759,521</li>
                            <li><strong>Input Size:</strong> 299×299×3</li>
                            <li><strong>Output Size:</strong> 299×299×3</li>
                            <li><strong>File Size:</strong> 29.6 MB</li>
                        </ul>
                        <h6>Model Architecture:</h6>
                        <pre class="bg-light p-3 mb-0" style="max-height: 300px; overflow-y: auto;"><code class="python"># U-Net Model Architecture
class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()
        self.enc1 = UNetBlock(6, 64)
        self.pool1 = nn.MaxPool2d(2)
        self.enc2 = UNetBlock(64, 128)
        self.pool2 = nn.MaxPool2d(2)
        self.bottleneck = UNetBlock(128, 256)
        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.dec1 = UNetBlock(256, 128)
        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.dec2 = UNetBlock(128, 64)
        self.final = nn.Conv2d(64, 3, kernel_size=1)</code></pre>
                    </div>
                </div>
                <div class="col-md-6">
                    <h5 class="mb-3">Key Components</h5>
                    <ul class="list-group">
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Contracting path (encoder)</li>
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Expansive path (decoder)</li>
                        <li class="list-group-item"><i class="fas fa-check text-success me-2"></i>Skip connections for preserving details</li>
                    </ul>
                    <div class="mt-4">
                        <h5 class="mb-3">Advantages</h5>
                        <ul class="list-unstyled">
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>Excellent feature preservation</li>
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>Context awareness for better enhancement</li>
                            <li><i class="fas fa-arrow-right text-primary me-2"></i>Robust performance on medical imagery</li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Enhancement Process -->
    <div class="card shadow-sm">
        <div class="card-header bg-dark text-white">
            <h2 class="h4 mb-0">Enhancement Process</h2>
        </div>
        <div class="card-body">
            <div class="row align-items-center">
                <div class="col-md-8">
                    <h5 class="mb-3">Combined Model Pipeline</h5>
                    <div class="alert alert-secondary">
                        <ol class="mb-0">
                            <li class="mb-2">Initial enhancement using SRCNN
                                <ul>
                                    <li>Feature extraction and mapping</li>
                                    <li>Initial quality improvement</li>
                                </ul>
                            </li>
                            <li class="mb-2">Feature refinement through U-Net
                                <ul>
                                    <li>Context-aware processing</li>
                                    <li>Detail preservation and enhancement</li>
                                </ul>
                            </li>
                            <li>Post-processing optimization
                                <ul>
                                    <li>Edge enhancement</li>
                                    <li>Contrast adjustment</li>
                                </ul>
                            </li>
                        </ol>
                    </div>
                </div>
                <div class="col-md-4">
                    <div class="text-center">
                        <i class="fas fa-arrow-right fa-3x text-primary mb-3"></i>
                        <p class="mb-0">Input Image</p>
                        <i class="fas fa-arrow-down fa-2x text-success my-3"></i>
                        <p class="mb-0">SRCNN Processing</p>
                        <i class="fas fa-arrow-down fa-2x text-success my-3"></i>
                        <p class="mb-0">U-Net Refinement</p>
                        <i class="fas fa-arrow-down fa-2x text-success my-3"></i>
                        <p class="mb-0">Enhanced Output</p>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock %}

<button id="toggleButton" class="btn btn-secondary float-end">Show U-Net</button>
<script>
document.getElementById('toggleButton').addEventListener('click', function() {
    var modelDetails = document.getElementById('modelDetails');
    if (this.innerHTML === 'Show U-Net') {
        modelDetails.innerHTML = '<div class="row"><div class="col-md-6"><h5 class="card-subtitle mb-3">Architecture Overview</h5><p>A convolutional network architecture designed for biomedical image segmentation and enhancement.</p><div class="alert alert-info"><h6>Model Specifications:</h6><ul class="list-unstyled mb-3"><li><strong>Parameters:</strong> 7,759,521</li><li><strong>Input Size:</strong> 299×299×3</li><li><strong>Output Size:</strong> 299×299×3</li><li><strong>File Size:</strong> 29.6 MB</li></ul><h6>Model Architecture:</h6><pre class="bg-light p-3 mb-0" style="max-height: 300px; overflow-y: auto;"><code class="python"># U-Net Model Architecture\nclass UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        self.enc1 = UNetBlock(6, 64)\n        self.pool1 = nn.MaxPool2d(2)\n        self.enc2 = UNetBlock(64, 128)\n        self.pool2 = nn.MaxPool2d(2)\n        self.bottleneck = UNetBlock(128, 256)\n        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.dec1 = UNetBlock(256, 128)\n        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        self.dec2 = UNetBlock(128, 64)\n        self.final = nn.Conv2d(64, 3, kernel_size=1)</code></pre></div></div></div>';
        this.innerHTML = 'Show SRCNN';
    } else {
        modelDetails.innerHTML = '<div class="row"><div class="col-md-6"><h5 class="card-subtitle mb-3">Architecture Overview</h5><p>A deep learning model specifically designed for image super-resolution and enhancement.</p><div class="alert alert-info"><h6>Model Specifications:</h6><ul class="list-unstyled mb-3"><li><strong>Parameters:</strong> 57,184</li><li><strong>Input Size:</strong> 299×299×3</li><li><strong>Output Size:</strong> 299×299×3</li><li><strong>File Size:</strong> 228 KB</li></ul><h6>Model Architecture:</h6><pre class="bg-light p-3 mb-0" style="max-height: 300px; overflow-y: auto;"><code class="python"># SRCNN Model Architecture\nclass SRCNN(nn.Module):\n    def __init__(self):\n        super(SRCNN, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=9, padding=4)\n        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding=2)\n        self.conv3 = nn.Conv2d(32, 3, kernel_size=5, padding=2)\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        x = self.relu(self.conv1(x))\n        x = self.relu(self.conv2(x))\n        x = self.conv3(x)\n        return x</code></pre></div></div></div>';
        this.innerHTML = 'Show U-Net';
    }
});
</script>